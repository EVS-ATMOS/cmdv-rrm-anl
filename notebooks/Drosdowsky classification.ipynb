{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Drosdowsky (1997) classification on sounding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates\n",
    "%matplotlib inline\n",
    "import metpy.calc as mpcalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path_sounding = '/home/rjackson/data/soundings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_sounding)times\n",
    "#     start_year = Start year of animation\n",
    "#     start_month = Start month of animation\n",
    "#     start_day = Start day of animation\n",
    "#     start_hour = Start hour of animation\n",
    "#     end_year = End year of animation\n",
    "#     end_month = End month of animation\n",
    "#     end_day = End day of animation\n",
    "#     end_minute = End minute of animation\n",
    "#     minute_interval = Interval in minutes between scans (default is 5)\n",
    "# This procedure acquires an array of sounding times between start_time and end_time. \n",
    "# Only 23 UTC is loaded following Pope et al. (2008)\n",
    "def get_sounding_times(start_year, start_month, start_day,\n",
    "                       start_hour, start_minute, end_year,\n",
    "                       end_month, end_day, end_hour, \n",
    "                       end_minute, minute_interval=5):\n",
    "\n",
    "    start_time = datetime(start_year,\n",
    "                          start_month,\n",
    "                          start_day,\n",
    "                          start_hour,\n",
    "                          start_minute,\n",
    "                          )\n",
    "    end_time = datetime(end_year,\n",
    "                        end_month,\n",
    "                        end_day,\n",
    "                        end_hour,\n",
    "                        end_minute,\n",
    "                        )\n",
    "    deltatime = end_time - start_time\n",
    "\n",
    "    if(deltatime.seconds > 0 or deltatime.minutes > 0):\n",
    "        no_days = deltatime.days + 1\n",
    "    else:\n",
    "        no_days = deltatime.days\n",
    "    \n",
    "    if(start_day != end_day):\n",
    "        no_days = no_days + 1\n",
    "        \n",
    "    days = np.arange(0, no_days, 1)\n",
    "    print('We are about to load sounding files for ' + str(no_days) + ' days')\n",
    "    \n",
    "    # Find the list of files for each day\n",
    "    cur_time = start_time\n",
    "\n",
    "    file_list = []\n",
    "    time_list = []\n",
    "    for i in days:\n",
    "        year_str = \"%04d\" % cur_time.year\n",
    "        day_str = \"%02d\" % cur_time.day\n",
    "        month_str = \"%02d\" % cur_time.month\n",
    "        format_str = (data_path_sounding +\n",
    "                      'twpsondewnpnC3.b1.' +\n",
    "                      year_str +\n",
    "                      month_str +\n",
    "                      day_str +\n",
    "                      '*.23*'\n",
    "                     '*custom.cdf')\n",
    "    \n",
    "          \n",
    "        data_list = glob.glob(format_str)\n",
    "        if(i % 100 == 0):\n",
    "            print(i)\n",
    "        for j in range(0, len(data_list)):\n",
    "            file_list.append(data_list[j])\n",
    "        cur_time = cur_time + timedelta(days=1)\n",
    "        \n",
    "   \n",
    "    # Parse all of the dates and time in the interval and add them to the time list\n",
    "    past_time = []\n",
    "    for file_name in file_list:\n",
    "        date_str = file_name[-26:-11]  \n",
    "        year_str = date_str[0:4]\n",
    "        month_str = date_str[4:6]\n",
    "        day_str = date_str[6:8]\n",
    "        hour_str = date_str[9:11]\n",
    "        minute_str = date_str[11:13]\n",
    "        second_str = date_str[13:15]\n",
    "                \n",
    "        cur_time = datetime(int(year_str),\n",
    "                            int(month_str),\n",
    "                            int(day_str),\n",
    "                            int(hour_str),\n",
    "                            int(minute_str),\n",
    "                            int(second_str))\n",
    "        time_list.append(cur_time)\n",
    "    \n",
    "    # Sort time list and make sure time are at least xx min apart\n",
    "    time_list.sort()\n",
    "    time_list_sorted = deepcopy(time_list)\n",
    "   \n",
    "    time_list_final = []\n",
    "    past_time = []\n",
    "    \n",
    "    for times in time_list_sorted: \n",
    "        \n",
    "        cur_time = times  \n",
    "        \n",
    "        if(past_time == []):\n",
    "            past_time = cur_time\n",
    "            \n",
    "        if(cur_time - past_time >= timedelta(minutes=minute_interval)\n",
    "           and cur_time >= start_time and cur_time <= end_time):\n",
    "            \n",
    "            time_list_final.append(cur_time)\n",
    "            past_time = cur_time\n",
    "               \n",
    "    return time_list_final\n",
    "\n",
    "# Get a Radar object given a time period in the CPOL dataset\n",
    "def get_sounding(time):\n",
    "    year_str = \"%04d\" % time.year\n",
    "    month_str = \"%02d\" % time.month\n",
    "    day_str = \"%02d\" % time.day\n",
    "    hour_str = \"%02d\" % time.hour\n",
    "    minute_str = \"%02d\" % time.minute\n",
    "    second_str = \"%02d\" % time.second\n",
    "    file_name_str = (data_path_sounding +\n",
    "                     'twpsondewnpnC3.b1.' +\n",
    "                     year_str +\n",
    "                     month_str +\n",
    "                     day_str +\n",
    "                     '.' +\n",
    "                     hour_str +\n",
    "                     minute_str +\n",
    "                     second_str +\n",
    "                     '.custom.cdf')\n",
    "    sounding = Dataset(file_name_str, mode='r')\n",
    "    return sounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load netCDF sounding data\n",
    "\n",
    "surface (assumed\n",
    "here to be 1013 hPa), 950, 925, 900, 850, 800, 750, 700,\n",
    "650, 600, 550, 500, 400, 300, 200, and 100 hPa (a total of\n",
    "16 levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we input the times and pressure levels to get sounding from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are about to load sounding files for 4749 days\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4493\n"
     ]
    }
   ],
   "source": [
    "start_year = 2002\n",
    "end_year = 2015\n",
    "\n",
    "sounding_times = get_sounding_times(start_year,1,1,0,1,\n",
    "                                    end_year,1,1,23,1)\n",
    "\n",
    "pres_levels = [1013, 950, 925, 900, 850, 800, 750, 700, \n",
    "               650, 600, 550, 500, 400, 300, 200, 100] \n",
    "print(len(sounding_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all of the soundings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.589316093909492% of soundings masked\n"
     ]
    }
   ],
   "source": [
    "## Save soundings at 16 levels for later\n",
    "\n",
    "u_soundings = np.zeros((len(sounding_times),16))\n",
    "v_soundings = np.zeros((len(sounding_times),16))\n",
    "t_soundings = np.zeros((len(sounding_times),16))\n",
    "z_soundings = np.zeros((len(sounding_times),16))\n",
    "dp_soundings = np.zeros((len(sounding_times),16))\n",
    "time_soundings = []\n",
    "pres_soundings = np.zeros((len(sounding_times),16))\n",
    "count = 0\n",
    "no_masked = 0\n",
    "\n",
    "for time in sounding_times:\n",
    "    if(time.month <= 4 or time.month >= 9):\n",
    "        if(time.hour == 23):\n",
    "            pres_index = []\n",
    "            # Load sounding file\n",
    "            Sounding_netcdf = get_sounding(time)\n",
    "\n",
    "            # Convert timestamps to datetime format        \n",
    "            p = Sounding_netcdf.variables['pres'][:]\n",
    "            u = Sounding_netcdf.variables['u_wind'][:]\n",
    "            v = Sounding_netcdf.variables['v_wind'][:]\n",
    "            t = Sounding_netcdf.variables['tdry'][:]\n",
    "            z = Sounding_netcdf.variables['alt'][:]\n",
    "            dp = Sounding_netcdf.variables['dp'][:]\n",
    "            \n",
    "            # Take levels from the sounding and place them into the array\n",
    "            \n",
    "            for pres in pres_levels:\n",
    "                pres_index.append(find_nearest(p,pres))\n",
    "           \n",
    "            \n",
    "            # Check for availability of 16 pressure levels\n",
    "            good_sounding = 1\n",
    "            for i in range(0,len(pres_levels)-1):\n",
    "                if(p[pres_index[i]] < pres_levels[i]-20 or\n",
    "                    p[pres_index[i]] > pres_levels[i]+20):\n",
    "                    good_sounding = 0\n",
    "                if(abs(u[pres_index[i]]) > 75 or\n",
    "                   abs(v[pres_index[i]]) > 75):\n",
    "                    good_sounding = 0\n",
    "            \n",
    "            u = u[pres_index]\n",
    "            v = v[pres_index]\n",
    "            t = t[pres_index]\n",
    "            z = z[pres_index]\n",
    "            dp = dp[pres_index]\n",
    "            \n",
    "            for i in range(0,len(u)):\n",
    "                if(u[i] < -75 or v[i] < -75 or\n",
    "                   u[i] is np.ma.masked or\n",
    "                   v[i] is np.ma.masked or\n",
    "                   dp[i] is np.ma.masked or\n",
    "                   t[i] is np.ma.masked or\n",
    "                   dp[i] < -99):\n",
    "                    good_sounding = 0\n",
    "            \n",
    "            if(t[0] < 0):\n",
    "                t[:] = float('nan')\n",
    "                good_sounding = 0\n",
    "                \n",
    "            # If pressure levels are not available, mask the entire sounding\n",
    "            if(good_sounding == 0):\n",
    "                no_masked = no_masked + 1\n",
    "            else:    \n",
    "                u_soundings[count][:] = u\n",
    "                v_soundings[count][:] = v\n",
    "                t_soundings[count][:] = t\n",
    "                dp_soundings[count][:] = dp\n",
    "                z_soundings[count][:] = z\n",
    "                time_soundings.append(time)\n",
    "                pres_soundings[count][:] = pres_levels\n",
    "                count = count + 1   \n",
    "                \n",
    "if(count % 100 == 0):\n",
    "    print(time)\n",
    "\n",
    "u_soundings = u_soundings[0:count-1][:]\n",
    "v_soundings = v_soundings[0:count-1][:]\n",
    "t_soundings = t_soundings[0:count-1][:]\n",
    "dp_soundings = dp_soundings[0:count-1][:]\n",
    "z_soundings = z_soundings[0:count-1][:]\n",
    "pres_soundings = pres_soundings[0:count-1][:]\n",
    "print(str((no_masked/(count+no_masked)*100)) + '% of soundings masked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-height sections\n",
    "\n",
    "Test the Drosdowsky (1997) classification over the two months of TWP-ICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_year = 2006\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "\n",
    "start_time = datetime(year=start_year, \n",
    "                      month=start_month, \n",
    "                      day=start_day)\n",
    "end_year = 2006\n",
    "end_month = 3\n",
    "end_day = 1\n",
    "\n",
    "end_time = datetime(year=end_year, \n",
    "                    month=end_month, \n",
    "                    day=end_day)\n",
    "\n",
    "indicies = []\n",
    "datenums = []\n",
    "i = 0\n",
    "for times in time_soundings:\n",
    "    if(times >= start_time and times <= end_time):\n",
    "        indicies.append(i)\n",
    "        datenums.append(dates.date2num(times))\n",
    "                        \n",
    "    i = i + 1\n",
    "    \n",
    "datelocs = [datetime.strptime('2006-01-01', \"%Y-%m-%d\"),\n",
    "            datetime.strptime('2006-01-15', \"%Y-%m-%d\"),\n",
    "            datetime.strptime('2006-02-01', \"%Y-%m-%d\"),\n",
    "            datetime.strptime('2006-02-15', \"%Y-%m-%d\")]\n",
    "\n",
    "x = dates.date2num(datelocs)\n",
    "plt.figure(figsize=(8,20))\n",
    "plt.subplot(311)\n",
    "X,Y = np.meshgrid(pres_levels, datenums)\n",
    "Z = u_soundings[indicies][:]\n",
    "CS = plt.contour(Y, X, Z)\n",
    "\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "plt.title('U (m/s)')\n",
    "plt.gca().set_xticks(x)\n",
    "\n",
    "# Set the xtick labels to correspond to just the dates you entered.\n",
    "plt.gca().set_xticklabels([date.strftime(\"%Y-%m-%d\") for date in datelocs])\n",
    "\n",
    "# Calculate the pressure weighted DLM for each timestep\n",
    "DLM = np.zeros(len(indicies))\n",
    "U_300100 = np.zeros(len(indicies))\n",
    "j = 0\n",
    "\n",
    "for i in indicies:\n",
    "    DLM[j] = sum(pres_levels[0:11]*u_soundings[i,0:11]/(sum(pres_levels[0:11])))\n",
    "    U_300100[j] = np.mean(u_soundings[i,13:15])\n",
    "    j = j + 1\n",
    "\n",
    "classification_Drosdowsky = np.zeros(len(DLM))\n",
    "j = 0\n",
    "N = 1\n",
    "break_spell = 0\n",
    "U = 2.5\n",
    "for i in range(0,len(DLM)):\n",
    "    if(np.mean(DLM[i-N:i]) > U*(N+1)/N and DLM[i] > 0):\n",
    "        if(U_300100[i] < 0):\n",
    "            N = N + 1\n",
    "        else:\n",
    "            if(N > 1):\n",
    "                classification_Drosdowsky[j-N+1:j-1] = 1\n",
    "                N = 1\n",
    "    else:\n",
    "        if(N > 1):\n",
    "            classification_Drosdowsky[j-N+1:j-1] = 1\n",
    "            N = 1\n",
    "    j = j + 1\n",
    "            \n",
    "plt.subplot(312)\n",
    "plt.plot_date(datenums,DLM)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('DLM U Surface-500 hPa [m/s]')\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot_date(datenums,classification_Drosdowsky)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Classification')\n",
    "plt.gca().set_yticks([0,1])\n",
    "plt.gca().set_yticklabels(['Break', 'Monsoon'])\n",
    "plt.ylim((-1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write classification from 2003 to 2015 to netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjackson/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/rjackson/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/rjackson/data/Drosdowsky.cdf'\n",
    "\n",
    "indicies = []\n",
    "datenums = []\n",
    "i = 0\n",
    "for times in time_soundings:\n",
    "    indicies.append(i)\n",
    "    datenums.append(dates.date2num(times)) \n",
    "    i = i + 1\n",
    "    \n",
    "# Calculate the pressure weighted DLM for each timestep\n",
    "DLM = np.zeros(len(indicies)-1)\n",
    "U_300100 = np.zeros(len(indicies)-1)\n",
    "year = np.zeros(len(indicies)-1)\n",
    "month = np.zeros(len(indicies)-1)\n",
    "day = np.zeros(len(indicies)-1)\n",
    "j = 0\n",
    "\n",
    "for i in range(0,len(indicies)-1):\n",
    "    DLM[j] = sum(pres_levels[0:11]*u_soundings[i,0:11]/(sum(pres_levels[0:11])))\n",
    "    U_300100[j] = np.mean(u_soundings[i,13:15])\n",
    "    year[j] = time_soundings[i].year\n",
    "    month[j] = time_soundings[i].month\n",
    "    day[j] = time_soundings[i].day\n",
    "    j = j + 1\n",
    "\n",
    "classification_Drosdowsky = np.zeros(len(DLM))\n",
    "j = 0\n",
    "N = 1\n",
    "break_spell = 0\n",
    "U = 2.5\n",
    "# Calculate Deep Layer Mean wind and classify time periods\n",
    "\n",
    "for i in range(0,len(DLM)-1):\n",
    "    if(np.mean(DLM[i-N:i]) > U*(N+1)/N and DLM[i] > 0):\n",
    "        if(U_300100[i] < 0):\n",
    "            N = N + 1\n",
    "        else:\n",
    "            if(N > 1):\n",
    "                classification_Drosdowsky[j-N+1:j-1] = 1\n",
    "                N = 1\n",
    "    else:\n",
    "        if(N > 1):\n",
    "            classification_Drosdowsky[j-N+1:j-1] = 1\n",
    "            N = 1\n",
    "    j = j + 1\n",
    "    \n",
    "out_netcdf = Dataset(file_path, mode='w')            \n",
    "out_netcdf.createDimension('time', len(classification_Drosdowsky))\n",
    "\n",
    "print(len(classification_Drosdowsky))\n",
    "groups_file = out_netcdf.createVariable('groups', 'i4', ('time',))\n",
    "groups_file.long_name = 'Pope classification regime'\n",
    "groups_file.units = '0 = Break, 1 = Monsoon'\n",
    "groups_file[:] = classification_Drosdowsky\n",
    "\n",
    "years_file = out_netcdf.createVariable('year', year.dtype, ('time',))\n",
    "years_file.long_name = 'Year'\n",
    "years_file.units = 'YYYY'\n",
    "years_file[:] = year\n",
    "\n",
    "month_file = out_netcdf.createVariable('month',  month.dtype, ('time',))\n",
    "month_file.long_name = 'Month'\n",
    "month_file.units = 'MM'\n",
    "month_file[:] = month\n",
    "\n",
    "day_file = out_netcdf.createVariable('day', day.dtype, ('time',))\n",
    "day_file.long_name = 'Day'\n",
    "day_file.units = 'DD'\n",
    "day_file[:] = day\n",
    "                                       \n",
    "out_netcdf.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
